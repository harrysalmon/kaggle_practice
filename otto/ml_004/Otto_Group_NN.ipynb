{
 "metadata": {
  "name": "",
  "signature": "sha256:0fcf090ebbe392ed8a2ef619b09e79ad0d7939a6d732d501731f6fb18ff2f537"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Otto Group Product Classification Challenge using nolearn/lasagne"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This short notebook is meant to help you getting started with nolearn and lasagne in order to train a neural net and make a submission to the Otto Group Product Classification Challenge.\n",
      "\n",
      "* [Otto Group Product Classification Challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge)\n",
      "* [Get the notebook from the Otto Group repository](https://github.com/ottogroup)\n",
      "* [Nolearn repository](https://github.com/dnouri/nolearn)\n",
      "* [Lasagne repository](https://github.com/benanne/Lasagne)\n",
      "* [A nolearn/lasagne tutorial for convolutional nets](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.preprocessing import StandardScaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne.layers import DenseLayer\n",
      "from lasagne.layers import InputLayer\n",
      "from lasagne.layers import DropoutLayer\n",
      "from lasagne.nonlinearities import softmax\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Utility functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_train_data(path):\n",
      "    df = pd.read_csv(path)\n",
      "#     print df.head()\n",
      "    X = df.values.copy()\n",
      "#     print X\n",
      "    np.random.shuffle(X)\n",
      "    X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
      "    encoder = LabelEncoder()\n",
      "    y = encoder.fit_transform(labels).astype(np.int32)\n",
      "    scaler = StandardScaler()\n",
      "    X = scaler.fit_transform(X)\n",
      "#     print X\n",
      "    return X, y, encoder, scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_test_data(path, scaler):\n",
      "    df = pd.read_csv(path)\n",
      "    X = df.values.copy()\n",
      "    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
      "    X = scaler.transform(X)\n",
      "    return X, ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_submission(clf, X_test, ids, encoder, name='my_neural_net_submission.csv'):\n",
      "    y_prob = clf.predict_proba(X_test)\n",
      "    with open(name, 'w') as f:\n",
      "        f.write('id,')\n",
      "        f.write(','.join(encoder.classes_))\n",
      "        f.write('\\n')\n",
      "        for id, probs in zip(ids, y_prob):\n",
      "            probas = ','.join([id] + map(str, probs.tolist()))\n",
      "            f.write(probas)\n",
      "            f.write('\\n')\n",
      "    print(\"Wrote submission to file {}.\".format(name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main_path = '/home/harry/Documents/git/kaggle/otto/'\n",
      "X, y, encoder, scaler = load_train_data(main_path + 'train.csv')\n",
      "print scaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test, ids = load_test_data(main_path + 'test.csv', scaler)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_classes = len(encoder.classes_)\n",
      "num_features = X.shape[1]\n",
      "print num_classes\n",
      "print num_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9\n",
        "93\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Train Neural Net"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers0 = [('input', InputLayer),\n",
      "           ('dense0', DenseLayer),\n",
      "           ('dropout', DropoutLayer),\n",
      "           ('dense1', DenseLayer),\n",
      "           ('output', DenseLayer)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net0 = NeuralNet(layers=layers0,\n",
      "                 \n",
      "                 input_shape=(None, num_features),\n",
      "                 dense0_num_units=200,\n",
      "                 dropout_p=0.5,\n",
      "                 dense1_num_units=200,\n",
      "                 output_num_units=num_classes,\n",
      "                 output_nonlinearity=softmax,\n",
      "                 \n",
      "                 update=nesterov_momentum,\n",
      "                 update_learning_rate=0.01,\n",
      "                 update_momentum=0.9,\n",
      "                 \n",
      "                 eval_size=0.2,\n",
      "                 verbose=1,\n",
      "                 max_epochs=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net0.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  DenseLayer        \t(None, 9)           \tproduces       9 outputs\n",
        "  DenseLayer        \t(None, 200)         \tproduces     200 outputs\n",
        "  DropoutLayer      \t(None, 200)         \tproduces     200 outputs\n",
        "  DenseLayer        \t(None, 200)         \tproduces     200 outputs\n",
        "  InputLayer        \t(None, 93)          \tproduces      93 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  0.917076\u001b[0m  |  \u001b[32m  0.671485\u001b[0m  |     1.365743  |     74.56%  |  7.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.697473\u001b[0m  |  \u001b[32m  0.631455\u001b[0m  |     1.104548  |     75.77%  |  6.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.660938\u001b[0m  |  \u001b[32m  0.611501\u001b[0m  |     1.080846  |     76.33%  |  6.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.637878\u001b[0m  |  \u001b[32m  0.596290\u001b[0m  |     1.069744  |     76.80%  |  5.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.625413\u001b[0m  |  \u001b[32m  0.587149\u001b[0m  |     1.065169  |     77.20%  |  6.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     6  |  \u001b[94m  0.612393\u001b[0m  |  \u001b[32m  0.578704\u001b[0m  |     1.058214  |     77.17%  |  6.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     7  |  \u001b[94m  0.599572\u001b[0m  |  \u001b[32m  0.571020\u001b[0m  |     1.050002  |     77.57%  |  6.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     8  |  \u001b[94m  0.591451\u001b[0m  |  \u001b[32m  0.567400\u001b[0m  |     1.042388  |     77.60%  |  6.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     9  |  \u001b[94m  0.583924\u001b[0m  |  \u001b[32m  0.561993\u001b[0m  |     1.039023  |     77.71%  |  6.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    10  |  \u001b[94m  0.575887\u001b[0m  |  \u001b[32m  0.560216\u001b[0m  |     1.027974  |     77.88%  |  5.6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    11  |  \u001b[94m  0.569191\u001b[0m  |  \u001b[32m  0.553932\u001b[0m  |     1.027546  |     78.16%  |  5.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    12  |  \u001b[94m  0.566992\u001b[0m  |  \u001b[32m  0.553157\u001b[0m  |     1.025011  |     78.17%  |  6.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    13  |  \u001b[94m  0.560126\u001b[0m  |  \u001b[32m  0.548605\u001b[0m  |     1.021000  |     78.30%  |  5.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    14  |  \u001b[94m  0.554108\u001b[0m  |  \u001b[32m  0.546113\u001b[0m  |     1.014638  |     78.46%  |  5.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    15  |  \u001b[94m  0.550263\u001b[0m  |  \u001b[32m  0.541923\u001b[0m  |     1.015390  |     78.78%  |  5.9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    16  |  \u001b[94m  0.547976\u001b[0m  |  \u001b[32m  0.541071\u001b[0m  |     1.012762  |     78.76%  |  5.8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    17  |  \u001b[94m  0.543790\u001b[0m  |  \u001b[32m  0.538979\u001b[0m  |     1.008927  |     78.83%  |  5.8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    18  |  \u001b[94m  0.543157\u001b[0m  |  \u001b[32m  0.536512\u001b[0m  |     1.012386  |     78.97%  |  5.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    19  |  \u001b[94m  0.538365\u001b[0m  |  \u001b[32m  0.534656\u001b[0m  |     1.006936  |     79.11%  |  6.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    20  |  \u001b[94m  0.533267\u001b[0m  |  \u001b[32m  0.533233\u001b[0m  |     1.000063  |     79.20%  |  5.8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/init.py:30: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
        "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
        "/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/layers/helper.py:52: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
        "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x7f720411ba28>,\n",
        "     batch_iterator_test=<nolearn.lasagne.BatchIterator object at 0x7f7200b12f90>,\n",
        "     batch_iterator_train=<nolearn.lasagne.BatchIterator object at 0x7f7200b12f50>,\n",
        "     dense0_num_units=200, dense1_num_units=200, dropout_p=0.5,\n",
        "     eval_size=0.2, input_shape=(None, 93),\n",
        "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
        "     loss=<function negative_log_likelihood at 0x7f7201f347d0>,\n",
        "     max_epochs=20, more_params={}, on_epoch_finished=(),\n",
        "     on_training_finished=(),\n",
        "     output_nonlinearity=<function softmax at 0x7f7201e0b488>,\n",
        "     output_num_units=9, regression=False,\n",
        "     update=<function nesterov_momentum at 0x7f7201f07c08>,\n",
        "     update_learning_rate=0.01, update_momentum=0.9,\n",
        "     use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prepare Submission File"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print os.getcwd()\n",
      "make_submission(net0, X_test, ids, encoder, name=main_path+'ml_004/outputs/their_nn.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/harry/Documents/git/kaggle/otto/ml_004\n",
        "Wrote submission to file /home/harry/Documents/git/kaggle/otto/ml_004/outputs/their_nn.csv."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}